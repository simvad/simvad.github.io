---
title: "EA is three radical ideas I want to protect"
date: 2023-11-13
category: "Meta"
author: "Peter Wildeford"
author_title: "Co-CEO Rethink Priorities"
author_bio: "Peter is the co-founder and co-CEO of Rethink Priorities. Prior to running Rethink Priorities, he was a data scientist in industry for five years. He is an avid hobbyist forecaster and consistently ranks well in forecasting competitions, including being a top 20 forecaster on Metaculus. Peter manages Rethink Priorities' longtermism and survey work."
author_image: "/images/peter-wildeford.jpeg"
original_url: "https://forum.effectivealtruism.org/posts/MP9qDZCXMaTJhiJ9u/ea-is-three-radical-ideas-i-want-to-protect"
---

*__Editor's Note: What follows is a brief excerpt from Peter's comprehensive article. For the full narrative and in-depth exploration, please [click here to read the complete post](https://forum.effectivealtruism.org/posts/MP9qDZCXMaTJhiJ9u/ea-is-three-radical-ideas-i-want-to-protect).__*

Essentially, effective altruism contains three radical ideas that I don't easily find in other communities. These three ideas are ideas I want to protect.

## Radical empathy

Humanity has long had a fairly narrow moral circle. [Radical Empathy](https://forum.effectivealtruism.org/posts/ehZK259et52Xnvw5F/radical-empathy) is the idea that there are many groups of people, or other entities, that are worthy of moral concern even if they don't look or act like us. Moreover, it's important to deliberately identify all entities worthy of moral concern so that we can ensure they are protected. I find effective altruism to be unique in extending moral concern to not just traditionally neglected farm animals and future humans (very important) -- but also to [invertebrates](https://forum.effectivealtruism.org/posts/T5fSphiK6sQ6hyptX/opinion-estimating-invertebrate-sentience) and [potential digital minds](https://80000hours.org/problem-profiles/artificial-sentience/). Effective altruists are also unique in trying to intentionally understand who might matter and why and actually incorporating this into the process of discovering how to best help the world. Asking the question "Who might matter that we currently neglect?" is a key question that is asked way too rarely.

We understand that while it's ok to have special concern for family and friends, we should generally aim to make altruistic decisions based on impartiality, not weighing people differently just because they are at a different level of geographic distance, a different level of temporal distance, a different species, or run cognition on a different substrate.

I worry that if we were to promote individual subcomponents of effective altruism, like pandemic preparedness or AI risk, we might not end up promoting radical empathy and we might end up missing entire classes of entities that matter. For example, I worry that one more subtle form of misaligned AI might be an AI that treats humans ok but adopts common human views on nonhuman animal welfare and perpetuates factory farming or abuse of a massive number of digital minds. The fact that effective altruism has somehow created a lot of AI developers that avoid eating meat and care about nonhuman animals is a big and fairly unexpected win. I think only some weird movement that somehow combined factory farming prevention with AI risk prevention could've created that.

## Scope sensitivity

I also really like that EAs are willing to ["shut up and multiply"](https://www.lesswrong.com/tag/shut-up-and-multiply). We're [scope sensitive](https://en.wikipedia.org/wiki/Scope_neglect). We're [cause neutral](https://forum.effectivealtruism.org/topics/cause-neutrality). Nearly everyone else in the world is not. Many people pick ways to improve the world based on vibes or personal experience, rather than through a systematic search of how they can best use their resources. Effective altruism understands that resources are limited and that we have to make hard choices between potential interventions and help 100 people instead of 10, even if helping the 10 people feels as or more satisfying. We understand "value per effort" and "bang for your buck" matter in philanthropy.

When thinking, we're also willing to think in bets and use expected value reasoning. When facing problems we can think probabilistically rather than in black and white. We can properly handle uncertainty.

I worry that by not communicating scope sensitivity when promoting subcomponents of effective altruism, we might be recruiting people who are unprepared to choose the right things when tackling the relevant problems. It's important that we empower people to be scope sensitive when deciding which risks to tackle and how to tackle them.

## Scout mindset

Lastly, the third and final factor I find really rare in the world is [scout mindset](https://en.wikipedia.org/wiki/The_Scout_Mindset), or the view that we should be open, collaborative, and truth-seeking in our understanding of what to do. While rare in the real world, this is abundant in effective altruism. We look for the truth rather than treat our [arguments as soldiers](https://www.lesswrong.com/tag/arguments-as-soldiers) or our [beliefs as attire](https://www.lesswrong.com/posts/nYkMLFpx77Rz3uo9c/belief-as-attire). We're open to being wrong, even about very fundamental things like our preferred ways to help others. We practice and [hone good epistemics](https://www.lesswrong.com/posts/xF96rk7yZtrjekiqZ/epistemic-progress-1). We hold each other to high standards of honesty, integrity, and friendliness.

I worry that by not communicating scout mindset when promoting components of effective altruism, we may recruit people who argue counterproductively, do not reason well, and ultimately hold us back as we try to collectively find the truth.

## Why this matters to me

These three radical views -- radical empathy, scope sensitivity, and scout mindset -- are so rare in the world that I rarely find people with just one of them, let alone all three. I think the effective altruism community has been amazing in cultivating a large group of talented and compelling people that hold these three views. I think that's precious and I want to protect that as much as I can.

It's natural for social movements to go through trials and tribulations. I was a part of the New Atheist movement during the acrimonious [Atheism Plus split](https://www.theguardian.com/commentisfree/belief/2012/sep/02/american-atheism-schism-spit-venom). I was a part of the animal rights movement during the shockingly poor behavior and more importantly terrible institutional handling of issues related to Wayne Pacelle, Nick Cooney, and others. While these issues are serious, it's normal for social movements to go through crisis -- what's more important is how we respond to that crisis.

I'm definitely ok with using other brands if that's what is most impactful. I don't want to cling stubbornly to my movement -- that wouldn't be a good use of scout mindset.

But I think I'm going to stick with effective altruism, at least as an internal motivation, as long as I think it effectively represents these three radical ideas and as long as no other movement does a better job at that.
